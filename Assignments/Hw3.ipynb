{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5440_Assignment3_chb2132.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdVtA23cm2f4"
      },
      "source": [
        "#`5440 Quant. ML/DatSci | SPRING 2021 | ASSIGNMENT 3 | UNI: CHB2132 `#\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWc01pptAtG4"
      },
      "source": [
        "##**Problem 1 (10 points)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h4mX-tbS23A"
      },
      "source": [
        "**Part (a) [5 points]**\n",
        "\n",
        "---\n",
        "\n",
        "*Write a computer program which computes the LASSO solution path (for all Î» in a given range) by implementing the cyclic coordinate descent equations derived in lecture, and the speedup due to precomputation suggested immediately thereafter in the lecture notes.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c35Jtjso1hHg"
      },
      "source": [
        "Coordinate Descent Algorithm Process\n",
        "---\n",
        "\n",
        "Repeat until convergence or max number of iterations:\n",
        "\n",
        "  \n",
        " 1. For $i = 0,1,...,N$\n",
        "\n",
        " 2. Compute $\\rho_i = \\sum_{m = 1}^M x_i^{m} (y^{m} - \\hat y^{m}_{pred} + \\theta_i x_i^{m} )$, \n",
        "\n",
        " 3. Set $\\theta_i = S(\\rho_i, \\lambda)$\n",
        "\n",
        "    * Note that if there is a constant term, it is not regularized ($\\theta_0 = \\rho_0$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw-pXbBVEhgo"
      },
      "source": [
        "#!pip install coordinatedescent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOGfctBpZ3VY"
      },
      "source": [
        "import math\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.core.display import display\n",
        "from IPython.core.debugger import Tracer\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "# %matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fRaHeGHq9mM"
      },
      "source": [
        "# function to compute linear regression value with lasso penalty\n",
        "def lasso(x, y, betas, lambduh):\n",
        "    return(np.sum(np.square(y - np.dot(x, betas))) / x.shape[0] + lambduh * np.sum(np.absolute(betas)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLZFKr-U5f38"
      },
      "source": [
        "# function to minimize linear regression with lasso penalty: using coord. descent method\n",
        "\n",
        "def coord_desc_cyclic(x, y, betas, lambduh, iter_max = 100):\n",
        "    \n",
        "    # initializing values\n",
        "    iter_val = 0\n",
        "    coord_val = 0\n",
        "    n = x.shape[0]\n",
        "    coord_max = x.shape[1]\n",
        "    iter_max  = iter_max * coord_max\n",
        "\n",
        "    # setting beta_val\n",
        "    beta_val = []\n",
        "    beta_val = np.zeros((iter_max, x.shape[1]), dtype = 'float')\n",
        "    beta_val[0] = betas\n",
        "\n",
        "    # looping in cyclic manner up to specified maximum iteration param\n",
        "    while iter_val < iter_max:\n",
        "        \n",
        "        # minimizing one coordinate at a time whilst looping through them\n",
        "        x_ij = pd.DataFrame(x).iloc[:, coord_val]\n",
        "        a_j = 2 * np.sum(np.square(x_ij)) / n\n",
        "        \n",
        "        x_mj = pd.DataFrame(x).iloc[:, [j for j in range(0, x.shape[1]) if j != coord_val]]\n",
        "        beta_mj = np.delete(betas, coord_val, 0)\n",
        "\n",
        "        dot_mj = np.dot(x_mj, beta_mj)\n",
        "        c_j = 2 * np.dot(np.transpose(x_ij), y - dot_mj) / n\n",
        "\n",
        "        beta_j = coeff_calc(c_j, a_j, lambduh)\n",
        "      \n",
        "        betas[coord_val] = beta_j\n",
        "        beta_val[iter_val] = betas\n",
        "\n",
        "        coord_val = coord_val + 1\n",
        "\n",
        "        if coord_val == coord_max:\n",
        "            coord_val = 0\n",
        "        iter_val = iter_val + 1\n",
        "\n",
        "    return beta_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLVJuusDE9yA"
      },
      "source": [
        "def lasso_plot(lambduh, x, y, beta_cyclic = []):\n",
        "\n",
        "    num_points = x.shape[0]\n",
        "    obj_cyclic = []\n",
        "    cyclic = True\n",
        "    obj_cyclic = np.zeros(num_points)\n",
        "\n",
        "    for i in range(0, num_points):\n",
        "      obj_cyclic[i] = lasso(x, y, beta_cyclic[i, :], lambduh)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(range(1, num_points + 1), obj_cyclic, label = 'cyclic coordinate descent')\n",
        "\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.title('Objective value vs. iteration when lambda = ' + str(lambduh))\n",
        "    ax.legend(loc = 'upper right')\n",
        "    plt.show()\n",
        "\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnk6YZvdFA4c"
      },
      "source": [
        "# computes mean squared error of prediction for actual test data output\n",
        "\n",
        "def test_MSE_calc(coeff_val, x_test_val, y_test_val):\n",
        "    test_MSE = np.mean((np.dot(x_test_val, coeff_val) - y_test_val)**2)\n",
        "    return test_MSE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-1tuymcLKJM"
      },
      "source": [
        "# function for coord-descent w/ cross-validation sol. (lambdas generated in log-space)\n",
        "\n",
        "def coord_desc_CV(x, y, lambda_count = 100, iter_max = 100, fold_count = 10):\n",
        "\n",
        "    if fold_count > x.shape[0]:\n",
        "        fold_count = (int)(x.shape[0]/2)\n",
        "\n",
        "    lambda_init = math.log10(max(abs(np.dot(x.T, y))) / x.shape[0])\n",
        " \n",
        "    lambda_val = np.logspace(-8, lambda_init, lambda_count)\n",
        "    lambda_val = lambda_val[np.argsort(-lambda_val)][::-1]\n",
        "    lambda_val = lambda_val[::-1]\n",
        "\n",
        "    print('cross-validation: lambda values used: ')\n",
        "    print(lambda_val)\n",
        "\n",
        "    fold_idx = range(0, x.shape[0])\n",
        "    fold_idx = np.random.permutation(fold_idx)\n",
        "\n",
        "    k_val = len(lambda_val)\n",
        "    score_final = np.zeros(k_val)\n",
        "\n",
        "    for k_iter in range(0, k_val):\n",
        "        score_init = np.zeros(fold_count)\n",
        "\n",
        "        for fold_iter in range(0, fold_count):\n",
        "\n",
        "            x_train, x_test, y_train, y_test = split_train_test(x, y, fold_count / 100)\n",
        "            beta_init = np.random.uniform(0, 0, x_train.shape[1])\n",
        "\n",
        "            rand_cd_beta = coord_desc_cyclic(x_train, y_train, beta_init, lambda_val[k_iter], iter_max)\n",
        "            score_init[fold_iter] = test_MSE_calc(rand_cd_beta[-1], x_test, y_test)\n",
        "\n",
        "        score_final[k_iter] = np.mean(score_init)\n",
        "\n",
        "    return lambda_val[np.argmin(score_final)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2mmUHFbF8Lw"
      },
      "source": [
        "# function that splits the generated data into a training and a test dataset based on ratio\n",
        "def split_train_test(x, y, p_ratio):\n",
        "\n",
        "    train_idx = np.random.randint(0, x.shape[0], round(x.shape[0] * p_ratio))\n",
        "    test_idx= np.delete(np.arange(0, x.shape[0]), train_idx)\n",
        "\n",
        "    x_train = np.asarray(pd.DataFrame(x).iloc[train_idx,])\n",
        "    y_train = np.asarray(pd.DataFrame(y).iloc[train_idx,0])\n",
        "\n",
        "    x_test = np.asarray(pd.DataFrame(x).iloc[test_idx,])\n",
        "    y_test = np.asarray(pd.DataFrame(y).iloc[test_idx,0])\n",
        "\n",
        "    return x_train, x_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knHArFnIFCkQ"
      },
      "source": [
        "# function to calculate the coefficients\n",
        "\n",
        "def coeff_calc(c_j, a_j, lambduh):\n",
        "    if c_j < -lambduh:\n",
        "        beta_j = (c_j + lambduh) / (a_j)\n",
        "    elif c_j > lambduh:\n",
        "        beta_j = (c_j - lambduh) / (a_j)\n",
        "    else:\n",
        "        beta_j = 0\n",
        "    return beta_j"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctyhb6OcSz9E"
      },
      "source": [
        "\n",
        "# **Part (b) [5 points]** \n",
        "\n",
        "---\n",
        "\n",
        "*Consider a linear model with known coefficients, such as:*\n",
        "\n",
        "$y = 3 x_1 -17 x_2 + 5 x_3 + \\epsilon,$\n",
        "\n",
        "$\\epsilon \\sim N(0,\\sigma^2), \\sigma = 1$\n",
        "\n",
        "*From this linear model, use a random number generator to generate a simulated data set of N = 1000 pairs (X, y) according to the model. Verify that, on this simulated data set, you get the same solution path as the glmnet program by Hastie, Tibshirani and Friedman. Note that glmnet is a package you can download in R.*\n",
        "\n",
        "*You may also use the python package discussed on Trevor Hastie's website:* https://web.stanford.edu/~hastie/glmnet_python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfsj-xyntErg"
      },
      "source": [
        "# function to generate sample data for specified parameters to be implemented with lasso/cv/cd funcs.\n",
        "\n",
        "def sample_data(sample_count = 1000, feature_count = 3, standardize = False, seed_val = 1984):\n",
        "\n",
        "  # x/input values for generated sample data\n",
        "  X = feature_count\n",
        "  feature_val = []\n",
        "  \n",
        "  # y/output values for generated sample data\n",
        "  coeffs = [3, -17, 5]\n",
        "  target_val = []\n",
        "\n",
        "  # initializing random generator in numpy\n",
        "  seed = seed_val\n",
        "  np.random.seed(seed)\n",
        "  \n",
        "  # generating features using  numpy random generators\n",
        "  N = sample_count\n",
        "  N = (int)(math.floor(N / 3) * 3)\n",
        "  sample_size = (int)(N / 3)\n",
        "    \n",
        "  x = pd.DataFrame([[0 for n_iter in range(N)] for x_iter in range(X)])\n",
        "\n",
        "  for j in range(0, X):\n",
        "\n",
        "    # first set of random method/range/scale for x value generation\n",
        "    x_min = 0\n",
        "    x_max = sample_size\n",
        "    \n",
        "    rand_loc = np.random.uniform(0, 100)\n",
        "    rand_scale = np.random.uniform(275, 678)\n",
        "\n",
        "    x.iloc[j, x_min:x_max] = np.array(np.random.normal(rand_loc, rand_scale, sample_size))\n",
        "\n",
        "    # second set of random method/range/scale for x value generation\n",
        "    x_min = sample_size\n",
        "    x_max = 2 * sample_size\n",
        "    \n",
        "    rand_min = np.random.normal(143, 199)\n",
        "    rand_max = np.random.normal(1443, 2442)\n",
        "\n",
        "    x.iloc[j, x_min:x_max] = np.array(np.random.uniform(rand_min, rand_max, sample_size))\n",
        "\n",
        "    # third set of random method/range/scale for x value generation\n",
        "    x_min = 2 * sample_size\n",
        "    x_max = 3 * sample_size\n",
        "    \n",
        "    rand_loc = np.random.uniform(888, 1337)\n",
        "    rand_scale = np.random.uniform(789, 1234)\n",
        "\n",
        "    x.iloc[j, x_min:x_max] = np.array(np.random.normal(rand_loc, rand_scale, sample_size))\n",
        "\n",
        "  feature_val = np.transpose(x)\n",
        "  feature_rand = feature_val + np.random.sample(X * N).reshape(N, X)\n",
        "\n",
        "  # set coefficients as given in the linear equation for all x values\n",
        "  coefficients = [3, -17, 5]\n",
        "\n",
        "  # generate epsilon/noise\n",
        "  noise = np.random.sample(N)\n",
        "\n",
        "  # generate 'clean' y-vals' - plug rand. feature vals into given eq.\n",
        "  target_clean = np.dot(feature_rand, coefficients)\n",
        "\n",
        "  # generate final output/target vars - add noise/error (epsilon) to 'clean' y-vals\n",
        "  target_val = target_clean + noise\n",
        "\n",
        "  # using lambda function to pass standardizing function method into both X and y data as nparray objects\n",
        "  if standardize == True:\n",
        "      feature_val = np.asarray(pd.DataFrame(feature_val).apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x))))\n",
        "      target_val = np.asarray((pd.DataFrame(target_val).apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))).iloc[:,0])\n",
        "\n",
        "  # sets X and y data as nparray object\n",
        "  feature_val = np.asarray(feature_val)\n",
        "  target_val = np.asarray(target_val)\n",
        "\n",
        "  return feature_val, target_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ3rpHEc7Aew"
      },
      "source": [
        "# generate the features for both the feature and target (x-val and y-val) for given eq./params.\n",
        "feature_val, target_val = sample_data(sample_count = 1000, feature_count = 3, standardize = False, seed_val = 1984)\n",
        "\n",
        "# split the dataset into train and test\n",
        "x_train, x_test, y_train, y_test = split_train_test(feature_val, target_val, p_ratio = 0.25)                                     \n",
        "\n",
        "max_iter = 100\n",
        "\n",
        "beta_init = np.random.uniform(0, 0, x_train.shape[1])\n",
        "\n",
        "# run cross-validation to get the best lambda\n",
        "best_lambda_CV = coord_desc_CV(x_train, y_train, lambda_count = 100, iter_max = 100, fold_count=10)\n",
        "print('Best lambda from cross validation: ' + str(best_lambda_CV))\n",
        "\n",
        "#run the cyclic coordinate descent algorithm with the best lambda obtained from cross validation\n",
        "cyclic_beta = coord_desc_cyclic(x_train, y_train, beta_init, best_lambda_CV, max_iter)\n",
        "\n",
        "print('beta values from the final iteration')\n",
        "display(cyclic_beta[-1])\n",
        "\n",
        "#plot the objective value vs iterations\n",
        "lasso_plot(best_lambda_CV, x_train, y_train, beta_cyclic = cyclic_beta)\n",
        "\n",
        "test_MSE = test_MSE_calc(cyclic_beta[-1], x_test, y_test)\n",
        "\n",
        "print('test mean square error: ' + str(test_MSE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYtpnjHaJwkY"
      },
      "source": [
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzTfgCUIYNRE"
      },
      "source": [
        "```\n",
        "Source: https://github.com/sumanbhagavathula/cycliccoordinatedescent/\n",
        "```"
      ]
    }
  ]
}
