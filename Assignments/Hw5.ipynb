{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5440_hw5_chb2132.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdVtA23cm2f4"
      },
      "source": [
        "#`ASSIGNMENT 5: NEURAL NETWORKS | UNI: CHB2132 `#\n",
        "##`5440 FIN. M.L./QUANT. | SPRING 2021 | PROF.  RITTER`\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h4mX-tbS23A"
      },
      "source": [
        "**Problem 1**\n",
        "\n",
        "---\n",
        "\n",
        "*Write a python program which implements the simple neural network for multi-class classification discussed in lecture. Use keras and TensorFlow. Hence solve the multi-class classification problem discussed in lecture. For completeness, the neural network structure is as follows. Derived features ùëçùëö are created from nonlinear functions on the reals, composed with linear combinations of the inputs.  Then the target ùëåùëò is modeled as a function of linear combinations of the ùëçùëö, as follows:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P45Qo6ubzF8"
      },
      "source": [
        "! pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoxfTuYFcasU"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras import layers\n",
        "from keras.datasets import mnist\n",
        "\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.datasets import mnist, imdb\n",
        "from tensorflow.keras.utils import to_categorical, model_to_dot\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Flatten, Embedding, SimpleRNN\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jakZnWU8capM"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 3\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVuPT_D6cano"
      },
      "source": [
        "# Load data\n",
        "(X_train, y_train), (X_val, y_val) = mnist.load_data()\n",
        "\n",
        "#print(f'Shape: {X_train[0].shape}')\n",
        "#X_train[0][:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEyziJSMr3IW"
      },
      "source": [
        "# Now let's reshape the data to fit into an neural net\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_val = X_val.reshape((X_val.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_val = X_val.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_val = to_categorical(y_val, NUM_CLASSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hksUv5Xss6i"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential() # base model class\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,))) # Dense layer, basic NN building block\n",
        "model.add(Dropout(0.5))  # dropout layer, helps to regularize training and avoid overfitting\n",
        "model.add(Dense(256, activation='relu')) # see keras docs for full list of activation functions (relu is usually a good choice)\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])  # specify the optimizer (gradient descent algo) and loss function,\n",
        "                                     # usually some form of cross entropy for catorical problems"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdurCBTFryp0"
      },
      "source": [
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXtBI75lsN54"
      },
      "source": [
        "*Evaluate the network*\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i00y3p6sKr9"
      },
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ab-zbfOcoiQ"
      },
      "source": [
        "## **`References`**\n",
        "\n",
        "```\n",
        "Feehan, Aion. 2021. 5430 NLP: Deep Learning Demo [jupyter notebook]. Columbia University in the city of New York.\n",
        "```"
      ]
    }
  ]
}
