{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5440_Checkpoint4_chb2132.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfMXMHtCzyoP"
      },
      "source": [
        "# Checkpoint 1\n",
        "---\n",
        "**Chlo√© Blanchard**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuuXze7kz1QY"
      },
      "source": [
        "### Initial Setup\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9KNnDAPuxJX"
      },
      "source": [
        "`Code Source: Professor Ritter, Columbia University`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWMpLF4ouwNS"
      },
      "source": [
        "import os\n",
        "import bz2\n",
        "\n",
        "import patsy\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import scipy\n",
        "import scipy.sparse\n",
        "\n",
        "from scipy.stats import gaussian_kde\n",
        "\n",
        "from statistics import median\n",
        "from statsmodels.formula.api import ols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whv99ARgkHT2"
      },
      "source": [
        "from google.colab import drive  \n",
        "drive.mount('/content/drive', force_remount= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2G0yr2QuwNX"
      },
      "source": [
        "model_dir = '/content/drive/MyDrive/APT-Portfolio/'\n",
        "\n",
        "def sort_cols(test):\n",
        "    return(test.reindex(sorted(test.columns), axis=1))\n",
        "\n",
        "frames = {}\n",
        "\n",
        "for year in [2003,2004,2005,2006,2007,2008,2009,2010]:\n",
        "    fil = model_dir + \"pandas-frames.\" + str(year) + \".pickle.bz2\"\n",
        "    frames.update(pickle.load( bz2.open( fil, \"rb\" ) ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cXWRDgGz5Te"
      },
      "source": [
        "### Problem 1\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFqc57_Qz5Fb"
      },
      "source": [
        "for x in frames:\n",
        "    frames[x] = sort_cols(frames[x])\n",
        "\n",
        "covariance = {}\n",
        "for year in [2003,2004,2005,2006,2007,2008,2009,2010]:\n",
        "    fil = model_dir + \"covariance.\" + str(year) + \".pickle.bz2\"\n",
        "    covariance.update(pickle.load( bz2.open(fil, \"rb\" ) ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiYYjHNExJE4"
      },
      "source": [
        "`Code Source: Professor Ritter, Columbia University`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1n5e5z7z-dS"
      },
      "source": [
        "### Problem 2\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvVB2hA6z9-X"
      },
      "source": [
        "def wins(x,a,b):\n",
        "    return(np.where(x <= a,a, np.where(x >= b, b, x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVxAJ_JAxKAQ"
      },
      "source": [
        "`Code Source: Professor Ritter, Columbia University`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OlM6vlRz_9t"
      },
      "source": [
        "### Problem 3\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8XzsCMpuwNX"
      },
      "source": [
        "def clean_nas(df):\n",
        "    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    for numeric_column in numeric_columns:\n",
        "        df[numeric_column] = np.nan_to_num(df[numeric_column])\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIPMcl8cxK1Y"
      },
      "source": [
        "`Code Source: Professor Ritter, Columbia University`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1JXckP50B50"
      },
      "source": [
        "### Problem 4\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zdDmItAuwNX"
      },
      "source": [
        "def density_plot(data, title):\n",
        "    density = gaussian_kde(data)\n",
        "    xs = np.linspace(np.min(data),np.max(data),200) \n",
        "    density.covariance_factor = lambda : .25 \n",
        "    density._compute_covariance() \n",
        "    plt.plot(xs,density(xs))\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "test = frames['20040102']\n",
        "density_plot(test['Ret'], 'Daily return pre-winsorization')\n",
        "density_plot(wins(test['Ret'],-0.2,0.2), 'Daily return winsorized')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhwcPH2sxLhI"
      },
      "source": [
        "`Code Source: Professor Ritter, Columbia University`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td0_Fw-NuwNX"
      },
      "source": [
        "*Q: Why might it be important to re-run this after passing it through bounds of b = -0.2 and b = 0.2 when running a regression with \"Ret\" as the \"Y variable\"?*\n",
        "\n",
        "**A: Winsorized estimators are usually more robust to outliers than their more standard forms. Before any kind of winsorization, the returns can be observed to have a very heavy right tail. We therefore want to run the data through a bounded domain of length 1 here so as to normalize our data and generate results that are robust to the particular skew to the RHS.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TJ4Y_VzuwNY"
      },
      "source": [
        "# Checkpoint 2\n",
        "---\n",
        "**Chlo√© Blanchard**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TqZuc7j108S"
      },
      "source": [
        "### Problem 1\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XiGA62exB5g"
      },
      "source": [
        "`Code Source: Professor Ritter, Columbia University`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqADdo9t1z2I"
      },
      "source": [
        "def get_formula(factors, Y):\n",
        "  \n",
        "    L = [\"0\"]\n",
        "    L.extend(factors)\n",
        "    return Y + \" ~ \" + \" + \".join(L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41eo7OOouwNY"
      },
      "source": [
        "def estimate_factor_returns(df):\n",
        "  \n",
        "   # rename df columns\n",
        "    df = df.rename(columns = {'1DREVRSL' : 'ONEDREVERSAL', 'EARNYILD' : 'EARNYIELD', 'SENTMT' : 'SENTIMENT'})\n",
        "    \n",
        "    ## build universe based on filters\n",
        "    estu = df.loc[df.IssuerMarketCap > 1e9].copy(deep=True)\n",
        "    \n",
        "    ## winsorize returns for fitting\n",
        "    estu['Ret'] = wins(estu['Ret'], -0.25, 0.25)\n",
        "\n",
        "    alp_factors = ['ONEDREVERSAL','EARNYIELD', 'VALUE', 'SENTIMENT'] \n",
        "\n",
        "    form = get_formula(alp_factors, \"Ret\")\n",
        "    model = ols(form, data = estu)\n",
        "\n",
        "    results = model.fit()\n",
        "    return(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g953Sx_H15lI"
      },
      "source": [
        "### Problem 2\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6vcVWQjuwNY"
      },
      "source": [
        "facret = {}\n",
        "\n",
        "for date in frames:\n",
        "    facret[date] = estimate_factor_returns(frames[date]).params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ4ys7CWuwNY"
      },
      "source": [
        "alpha_factors = ['ONEDREVERSAL', 'EARNYIELD', 'VALUE', 'SENTIMENT']\n",
        "\n",
        "my_dates = sorted(list(map(lambda date: pd.to_datetime(date, format='%Y%m%d'),frames.keys())))\n",
        "\n",
        "facret_df = pd.DataFrame(index = my_dates) \n",
        "\n",
        "for dt in my_dates:\n",
        "\n",
        "     for alp in alpha_factors:\n",
        "        \n",
        "        facret_df.at[dt, alp] = facret[dt.strftime('%Y%m%d')][alp]\n",
        "\n",
        "facret_df.cumsum().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKWTnp2dxMvQ"
      },
      "source": [
        "`Code Source: Professor Ritter, Columbia University`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b_T0Sjudn67"
      },
      "source": [
        "# Checkpoint 3\n",
        "---\n",
        "**Chlo√© Blanchard**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YrtOG_BdpIo"
      },
      "source": [
        "### Problem 1\n",
        "---\n",
        "* Write code that adds a column tracking prev. day holdings:\n",
        "  \n",
        "  * Initialized to zero weights for all assets when backtest first starts\n",
        "  * Prev. day portfolio weights by estimating trade size *(therefore transaction costs)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFh5qCxRgFms"
      },
      "source": [
        "`Code Source: Professor Ritter, Columbia University`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt2FDzdHf_or"
      },
      "source": [
        "prev_day = frames['Ret']\n",
        "print(prev_day)\n",
        "\n",
        "def (df):\n",
        "\n",
        "    form = get_formula(alp_factors, \"Ret\")\n",
        "    model = ols(form, data = estu)\n",
        "\n",
        "    results = model.fit()\n",
        "    return(results)\n",
        "    \n",
        "# rename df columns\n",
        "    df = df.rename(columns = {'1DREVRSL' : 'ONEDREVERSAL', 'EARNYILD' : 'EARNYIELD', 'SENTMT' : 'SENTIMENT'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iASoPJapN_ag"
      },
      "source": [
        "def h_star_calc(risk_aver = 1.0e-6, Q, Q_T, specVar, alpha_vec, h_0, Lambda):\n",
        "  \n",
        "  def calc_star(h):\n",
        "\n",
        "        tmp = 0.0\n",
        "        tmp += 0.5 * risk_aver * np.sum( np.matmul(Q, h) ** 2 )\n",
        "\n",
        "        # Specific variance is diagonal (matmul not needed)\n",
        "        tmp += 0.5 * risk_aver * np.dot(h ** 2, specVar)\n",
        "        tmp -= np.dot(h, alpha_vec)\n",
        "        tmp += np.dot( (h - h_0) ** 2, Lambda)\n",
        "\n",
        "        return(tmp)\n",
        "\n",
        "        def grad_star(h):\n",
        "\n",
        "        g = risk_aver * (h * specVar + np.matmul(Q_T, np.matmul(Q, h))) - alpha_vec + 2 * Lambda * (h - h_0)\n",
        "\n",
        "        return np.asarray(g)\n",
        "\n",
        "    optimizer_result = scipy.optimize.fmin_l_bfgs_b(calc_star, np.asarray(h_0), fprime = grad_star)\n",
        "\n",
        "    return optimizer_result[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puo24OEYdsF3"
      },
      "source": [
        "### Problem 2\n",
        "---\n",
        "* Build universe based on filters: select stock universe based on market cap, keeping companies w/ $1B+ valuation:\n",
        "\n",
        "  * Include companies in prev day's holdings, even if on current day, the company no longer meets $1B valuation\n",
        "  * Write code which performs indicated calculations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-pwdQeFTltw"
      },
      "source": [
        "def get_universe(df):\n",
        "    \n",
        "    ## build universe based on filters\n",
        "    estu = df.loc[df.IssuerMarketCap > 1e9].copy(deep=True)\n",
        "    \n",
        "    ## winsorize returns for fitting\n",
        "    estu['Ret'] = wins(estu['Ret'], -0.25, 0.25)\n",
        "\n",
        "    alp_factors = ['ONEDREVERSAL','EARNYIELD', 'VALUE', 'SENTIMENT'] \n",
        "\n",
        "    form = get_formula(alp_factors, \"Ret\")\n",
        "    model = ols(form, data = estu)\n",
        "\n",
        "    results = model.fit()\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMggRCzC5DuW"
      },
      "source": [
        "universe = pf_df['pd_weights' >= 1000000000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiEPE_QPdsD6"
      },
      "source": [
        "### Problem 3\n",
        "---\n",
        "* Write function setdiff to compute set-wise difference of All Factor Set - Alpha Factor Set = Non-Alpha Factor Set: **\"Risk factor\"** Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMtLQ5tFf-kb"
      },
      "source": [
        "def set_diff(all_factors):\n",
        "  risk_factors = universe_df - alpha_factors\n",
        "  return risk_factors\n",
        "\n",
        "setdiff(universe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQqQxBI6dsB5"
      },
      "source": [
        "### Problem 4\n",
        "---\n",
        "* Write a direct analogue of the model.matrix function in R: model_matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oCTmyX-I61n"
      },
      "source": [
        "# from rdrr.io - R documentation for stats::model.matrix()\n",
        "# Note: need to verify source documentation as this might be incorrect\n",
        "\n",
        "ff <- log(Volume) ~ log(Height) + log(Girth)\n",
        "utils::str(m <- model.frame(ff, trees))\n",
        "mat <- model.matrix(ff, m)\n",
        "\n",
        "dd <- data.frame(a = gl(3,4), b = gl(4,1,12)) # balanced 2-way\n",
        "options(\"contrasts\") # typically 'treatment' (for unordered factors)\n",
        "model.matrix(~ a + b, dd)\n",
        "model.matrix(~ a + b, dd, contrasts = list(a = \"contr.sum\"))\n",
        "model.matrix(~ a + b, dd, contrasts = list(a = \"contr.sum\", b = contr.poly))\n",
        "m.orth <- model.matrix(~a+b, dd, contrasts = list(a = \"contr.helmert\"))\n",
        "crossprod(m.orth) # m.orth is  ALMOST  orthogonal\n",
        "# invalid contrasts.. ignored with a warning:\n",
        "stopifnot(identical(\n",
        "   model.matrix(~ a + b, dd),\n",
        "   model.matrix(~ a + b, dd, contrasts.arg = \"contr.FOO\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSdc7fo5f6_B"
      },
      "source": [
        "def model_matrix(function, df):\n",
        "    dmat = dmatrix(function, df)\n",
        "    return dmat\n",
        "\n",
        "industries = ['AERODEF', 'AIRLINES', 'ALUMSTEL', 'APPAREL', 'AUTO', 'BANKS', \n",
        "              'BEVTOB', 'BIOLIFE', 'BLDGPROD', 'CHEM', 'CNSTENG', 'CNSTMACH', \n",
        "              'CNSTMATL', 'COMMEQP', 'COMPELEC', 'COMSVCS', 'CONGLOM', \n",
        "              'CONTAINR', 'ELECEQP', 'ELECUTIL', 'FOODPROD', 'FOODRET', \n",
        "              'GASUTIL', 'HLTHEQP', 'HLTHSVCS', 'HOMEBLDG', 'HOUSEDUR', \n",
        "              'INDMACH', 'INDMOM', 'INSURNCE', 'INTERNET', 'LEISPROD', \n",
        "              'LEISSVCS', 'LIFEINS', 'LITREVRSL', 'MEDIA', 'MGDHLTH', \n",
        "              'MGMTQLTY', 'OILGSCON', 'OILGSDRL', 'OILGSEQP', 'OILGSEXP', \n",
        "              'PAPER', 'PHARMA', 'PRECMTL', 'PSLPROD', 'REALEST', 'RESTAUR', \n",
        "              'ROADRAIL', 'SEMICOND', 'SEMIEQP', 'SOFTWARE', 'SPLTYRET', \n",
        "              'SPTYCHEM', 'SPTYSTOR', 'TELECOM', 'TRADECO']\n",
        "\n",
        "factors = ['BETA', 'MOMENTUM', 'VALUE', 'DISTRIB', 'DIVFIN', 'DIVYILD', \n",
        "                 'DWNRISK', 'EARNQLTY', 'EARNYILD','GROWTH', 'LEVERAGE', \n",
        "                 'LIQUIDITY', 'MOMENTUM', 'MULTUTIL', 'PROFIT', 'PROSPECT', \n",
        "                 'RESVOL', 'SEASON', 'SENTMT', 'SIZE', 'STREVRSL']\n",
        "\n",
        "date = '20080808'\n",
        "function = \"Ret ~ 0 +\" + \"+\".join(industries) + \"+\".join(factors)\n",
        "\n",
        "X = model_matrix(function, frames[date])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laYNPp2rdr_z"
      },
      "source": [
        "### Problem 5\n",
        "---\n",
        "* Transform risk (volatility) data to decimal form then square to compute vector containing specific var for each stock in universe:\n",
        "```\n",
        "specVar = (0.01 * universe['SpecRisk']) ** 2\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZcLoiI0f8uN"
      },
      "source": [
        "def risk_vect(universe):\n",
        "  var_vect = []\n",
        "  for frame in frames:\n",
        "  # apply to each stock \n",
        "    specVar = (0.01 * universe['SpecRisk']) ** 2\n",
        "    var_vect.append(specVar)\n",
        "  return var_vect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIUx-scndr2n"
      },
      "source": [
        "### Problem 6\n",
        "---\n",
        "* Create factor covariance matrix: data provides precomputed factor covs\n",
        "```\n",
        "covariance = {'key = date' : 'value = df of factor covariance data'}\n",
        "```\n",
        "* Write function: input is covariance, computes diagonalized matrix\n",
        "  * Rescale fcov from %$^2$ to decimal$^2$ squared $(fcov\\times.01)$\n",
        "  * Prevents optimizer from designing strategies that trade based on corr(factors) such as non-stationary correlations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN2FWYIAf86c"
      },
      "source": [
        "def fcov_matrix(covariance):\n",
        "  diag_matrix = covariance \n",
        "  diag_matrix = ((diag_matrix ** 0.5) * 0.01) ** 2\n",
        "  return diag_matrix "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkWh6fvGdrc9"
      },
      "source": [
        "### Problem 7\n",
        "---\n",
        "* A large order, as it is executed in the market, usually exerts pressure on the price of the security, in the same direction as the trading \n",
        "* To measure stock order size: compare to avg daily volume (ADV) in stock\n",
        "  * Don‚Äôt calc ADV, proxy by assuming each stock trades at ~$.01$ $\\times$ total issuer-level market capitalization in a typical day\n",
        "  * IssuerMarketCap is in pandas frames\n",
        "* Large orders in this metric predicted to cause greater price impact\n",
        "* Simplest predicted impact model assumes linear relationship btw ADV fraction and price impact\n",
        "* Example:\n",
        "  * If each $1$% ADV traded in $i^{th}$ security causes move of $0.1%$ in price $ùëÉ_ùëñ$:\n",
        "  * $\\Delta P_i = \\lambda_i(h_{i}^{*} - h_{i}^{0})$, where $\\lambda_i = \\frac{0.1}{ADV_i}$\n",
        "  * $‚Ñé^‚àó$: optimal portfolio we seek\n",
        "  * $‚Ñé^0$: portfolio we came into day with, i.e. **inventory positions**\n",
        "* Write function to compute total transaction costs using this model\n",
        "* Express the costs as a quadratic function with a diagonal matrix $\\Lambda$ (Lambda)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heBZp1v-n-tl"
      },
      "source": [
        "def total_transcosts(df):\n",
        "  trans_costs = []\n",
        "  for frame in frames:\n",
        "  # express costs as quadratic function w/ diag\n",
        "    trans =  0.01 * frame['ISSUERMARKETCAP'] * (h_star[frame] - h_0[frame]\n",
        "    trans_costs.append(trans)\n",
        "  return trans_costs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE6ugtH4dxXh"
      },
      "source": [
        "### Problem 8\n",
        "---\n",
        "* Calculating portfolio risk attributable to risk factors $‚Ñé^ùëá ùëã ùêπ ùëã^ùëá ‚Ñé$ can become computationally infeasible/slow\n",
        "* Using matrix factorization:\n",
        "  * Choose order of matrix multiplications to avoid creating ùëõ√óùëõ matrix\n",
        "  * Analogous to technique that makes L-BFGS optimizer so efficient\n",
        "  * Simple matrix factorization: $Q := F^{1/2}X^T$\n",
        "is defined s.t. $Q^T Q = X F X^T$\n",
        "* Write code to compute Q and the factorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAl5kKZBf9ST"
      },
      "source": [
        "def calc_Q(F, X, h):\n",
        "  # compute Q, Q_T\n",
        "  Q = F ** 0.5 * X.T\n",
        "  Q_T = Q.T\n",
        "  # matrix factorization\n",
        "  pf = h.T * Q * Q_T * h\n",
        "  return Q, pf\n",
        "\n",
        "calc_Q(F1, X1, h1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um5qDnXBdygC"
      },
      "source": [
        "### Problem 9\n",
        "---\n",
        "* Objective function: factor risk + idiosyncratic risk - expected portfolio return + transaction costs:\n",
        " * $f(h) = \\frac{1}{2} k h^T Q^T Q h + \\frac{1}{2} k h^T D h - \\alpha^T h + (h - h_0)^T \\wedge (h - h_0)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6dWbYXmf9kP"
      },
      "source": [
        "def obj_function(h, k, Q, alpha, D):\n",
        "  #factor risk + idiosyncratic risk - E[portfolio return] + transaction costs\n",
        "  obj_f = 0.5 * k * h.T * Q.T * Q * h + 0.5 * k * h.T * D * h - alpha.T * h + (h - h_0).T \n",
        "  return obj_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djsMRalQdzs1"
      },
      "source": [
        "### Problem 10\n",
        "---\n",
        "* Compile steps into a unified form_optimal_portfolio function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY9HCXya4-w4"
      },
      "source": [
        "universe = pf_df['pd_weights' >= 1000000000]\n",
        "\n",
        "def form_optimal_portfolio(df, prev_day, risk_aver = 1.0e-6):\n",
        "\n",
        "  ## merging vect of yesterday's holdings with new dataframe to create portfolio\n",
        "  ## prev_day: vector of prev_day inventory pos. held over (holdings from yest.)\n",
        "  df = df.merge(prev_day, how = 'left', on = 'ID')\n",
        "\n",
        "  # removing na values/cleaning dataframe\n",
        "  df = clean_nas(df)\n",
        "\n",
        "  # changing specific risk values from 0 to median risk value (no inf divisions)\n",
        "  df.loc[df['SpecRisk'] == 0]['SpecRisk'] = median(df['SpecRisk'])\n",
        "  \n",
        "  # creating variable for universe by calling get_uni on dataframe\n",
        "  universe = get_universe(df)\n",
        "\n",
        "  # adding date and outputting date value\n",
        "  date = str(int(universe['DataDate'][1]))\n",
        "  print(date, end = \" \")\n",
        "\n",
        "  # pull the list of factors in our portfolio\n",
        "  all_factors = factors_from_names(list(universe))\n",
        "  \n",
        "  # compute setdiff: all factors - alpha factors = risk_factors \n",
        "  risk_factors = setdiff(all_factors, alpha_factors)\n",
        "  \n",
        "  h_0 = universe['h.opt.previous']\n",
        "\n",
        "  X = model_matrix(get_formula(risk_factors, \"SpecRisk\"), universe)\n",
        "  XT = X.transpose()\n",
        "\n",
        "  specVar = (0.01 * universe['SpecRisk']) ** 2\n",
        "  Fvar = diagonal_factor_cov(date, X)\n",
        "  \n",
        "  # get lambda matrix and X_alpha matrix using alpha factor set, Returns, uni\n",
        "  Lambda = get_lambda(universe)\n",
        "  X_alpha = model_matrix(get_formula(alpha_factors, \"Ret\"), data = universe)\n",
        "  \n",
        "  # Collapse alphas into one alpha vector (most trivial alpha combination)\n",
        "  # In reality: done by some sophisticated stats not linear combination of af's\n",
        "\n",
        "  alpha_vec = 1e-4 * rowSums(X_alpha)\n",
        "  \n",
        "  # Precompute matrix + transpose for efficiency\n",
        "  Q = np.matmul(scipy.linalg.sqrtm(Fvar), XT);\n",
        "  Q_T = Q.transpose();\n",
        "\n",
        "  h_star = h_starred(risk_aversion, Q, Q_T, specVar, alpha_vec, h_0, Lambda)\n",
        "  opt_portfolio = pd.DataFrame(data = {\"ID\" : universe['ID'], \"h.opt\" : h_star})\n",
        "  \n",
        "  risk_exposures = get_risk_exposures(X, X_T, h_star)\n",
        "  \n",
        "  portfolio_alpha_exposure = get_portfolio_alpha_exposure(X_alpha, h_star)\n",
        "  total_transaction_costs = get_total_transaction_costs(h_0, h_star, Lambda)\n",
        "  \n",
        "  return {\n",
        "      \"opt.portfolio\" : opt_portfolio,\n",
        "      \"risk.exposures\" : risk_exposures,\n",
        "      \"alpha.exposures\" : portfolio_alpha_exposure,\n",
        "      \"total.cost\" : total_transaction_costs\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D6ohu_4xOCE"
      },
      "source": [
        "`Code Source: Professor Ritter, Columbia University`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leXU_8K-LdZm"
      },
      "source": [
        "# Checkpoint 4\n",
        "---\n",
        "**Chlo√© Blanchard**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbJTcxebLPZl"
      },
      "source": [
        "### Problem 1\n",
        "---\n",
        "*Trade List: the vector of trades which, when added to the previous holdings, gives the new target portfolio.*\n",
        "\n",
        "* Define a function which takes the previous holdings, and the result of our optimization function, and outputs a trade list\n",
        "```\n",
        "build_tradelist(prev_holdings, opt_result)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoCPBI_oLc8x"
      },
      "source": [
        "def build_tradelist(prev_holdings, opt_result, frames):\n",
        "    \n",
        "    frame = pd.DataFrame(frames)\n",
        "    frame = frame[opt_result] = frame.set_index('DataDate')\n",
        "\n",
        "    portfolio = pd.concat(frame, axis=1)\n",
        "    return_stocks = portfolio.pct_change()\n",
        "\n",
        "    number_of_portfolios = 2000\n",
        "    RF = 0\n",
        "\n",
        "    portfolio_returns = []\n",
        "    portfolio_risk = []\n",
        "    sharpe_ratio_port = []\n",
        "    portfolio_weights = []\n",
        "\n",
        "    for portfolio in range (number_of_portfolios):\n",
        "\n",
        "        #generate a w random weight of lengt of number of stocks\n",
        "        weights = np.random.random_sample((len(stocks)))\n",
        "\n",
        "        weights = weights / np.sum(weights)\n",
        "        annualize_return = np.sum((return_stocks.mean() * weights) * 252)\n",
        "        portfolio_returns.append(annualize_return)\n",
        "\n",
        "        #variance\n",
        "        matrix_covariance_portfolio = (return_stocks.cov())*252\n",
        "        portfolio_variance = np.dot(weights.T,np.dot(matrix_covariance_portfolio, weights))\n",
        "        portfolio_standard_deviation= np.sqrt(portfolio_variance) \n",
        "        portfolio_risk.append(portfolio_standard_deviation)\n",
        "\n",
        "        #sharpe_ratio\n",
        "        sharpe_ratio = ((annualize_return- RF)/portfolio_standard_deviation)\n",
        "        sharpe_ratio_port.append(sharpe_ratio)\n",
        "\n",
        "        portfolio_weights.append(weights)\n",
        "\n",
        "        portfolio_risk = np.array(portfolio_risk)\n",
        "        portfolio_returns = np.array(portfolio_returns)\n",
        "        sharpe_ratio_port = np.array(sharpe_ratio_port)\n",
        "\n",
        "    return (portfolio_risk, portfolio_returns, sharpe_ratio_port, portfolio_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz62pfZHR8rd"
      },
      "source": [
        "`Code Source: https://codingandfun.com/portfolio-optimization-with-python/`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DEaoulBLPWM"
      },
      "source": [
        "### Problems 2 & 3\n",
        "---\n",
        "*Ensure that your code is structured in such a way that, since n is large, we never form an n √ó n matrix either in the calculation of the objective function, the calculation of the gradient, or in the Hessian used by the L-BFGS descent method.*\n",
        "\n",
        "* Write a python function which will walk through each day, calculating the optimal portfolio weights and trade list\n",
        "\n",
        "*APT model entails associated reductions of the first and second moments of the asset returns. Using these reductions, the APT model allows us to attribute not only risk (variance), but also return or P&L. The portfolio‚Äôs one-period P&L is given by idiosyncratic plus factor contributions.*\n",
        "\n",
        "* Write a python function which plots the cumulative sum of the idiosyncratic contribution and risk factor contributions over time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbHT2GuuLPoe"
      },
      "source": [
        "# time series plot of idiosyncratic risk (variance/stdev) + alpha factors + beta factors\n",
        "# aggregate of long, short, net positions + gross market value + trade volume (USD)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(portfolio_risk, portfolio_returns, c=portfolio_returns / portfolio_risk) \n",
        "plt.xlabel('volatility')\n",
        "plt.ylabel('returns')\n",
        "plt.colorbar(label='Sharpe ratio')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdmAF1y-R7d6"
      },
      "source": [
        "`Code Source: https://codingandfun.com/portfolio-optimization-with-python/`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XONFCc3dLRNG"
      },
      "source": [
        "### Problem 4\n",
        "---\n",
        "* Calculate the sum of long positions, short positions, net positions, gross market value, and amount of dollars traded\n",
        "\n",
        "* Plot them all together as time series on the same graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5TIt6aPLkp2"
      },
      "source": [
        "# plot of time series graph\n",
        "# aggregate of long, short, net positions + gross market value + trade volume (USD)\n",
        "\n",
        "porfolio_metrics = [portfolio_returns,portfolio_risk,sharpe_ratio_port, portfolio_weights] \n",
        "\n",
        "portfolio_dfs = pd.DataFrame(porfolio_metrics)\n",
        "portfolio_dfs = portfolio_dfs.T\n",
        "portfolio_dfs.columns = ['Port Returns','Port Risk','Sharpe Ratio','Portfolio Weights']\n",
        "\n",
        "#convert from object to float the first three columns.\n",
        "for col in ['Port Returns', 'Port Risk', 'Sharpe Ratio']:\n",
        "    portfolio_dfs[col] = portfolio_dfs[col].astype(float)\n",
        "\n",
        "    #portfolio with the highest Sharpe Ratio\n",
        "    Highest_sharpe_port = portfolio_dfs.iloc[portfolio_dfs['Sharpe Ratio'].idxmax()]\n",
        "    #portfolio with the minimum risk \n",
        "    min_risk = portfolio_dfs.iloc[portfolio_dfs['Port Risk'].idxmin()]\n",
        "\n",
        "    #Highest_sharpe_port\n",
        "    print(Highest_sharpe_port)\n",
        "    print(min_risk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09JEgTIlLPTN"
      },
      "source": [
        "`Code Source: https://codingandfun.com/portfolio-optimization-with-python/`"
      ]
    }
  ]
}
